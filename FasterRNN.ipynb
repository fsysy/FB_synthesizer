{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongmunchoi/code/nlp/lib/python3.6/site-packages/torch/cuda/__init__.py:52: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n",
      "Downloading: \"https://download.pytorch.org/models/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\" to /home/jongmunchoi/.cache/torch/hub/checkpoints/maskrcnn_resnet50_fpn_coco-bf2d0c1e.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc4df77997324f1bbdbcdf6bb8fe1880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=178090079.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jongmunchoi/code/nlp/lib/python3.6/site-packages/torch/nn/functional.py:3103: UserWarning: The default behavior for interpolate/upsample with float scale_factor changed in 1.6.0 to align with other frameworks/libraries, and now uses scale_factor directly, instead of relying on the computed output size. If you wish to restore the old behavior, please set recompute_scale_factor=True. See the documentation of nn.Upsample for details. \n",
      "  warnings.warn(\"The default behavior for interpolate/upsample with float scale_factor changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]  [  0/219]  eta: 0:49:34  lr: 0.000028  loss: 4.7164 (4.7164)  loss_classifier: 0.5309 (0.5309)  loss_box_reg: 0.0492 (0.0492)  loss_mask: 2.5041 (2.5041)  loss_objectness: 1.4119 (1.4119)  loss_rpn_box_reg: 0.2203 (0.2203)  time: 13.5809  data: 0.3131\n",
      "Epoch: [0]  [ 10/219]  eta: 0:30:15  lr: 0.000257  loss: 2.2441 (2.2928)  loss_classifier: 0.4242 (0.3728)  loss_box_reg: 0.0492 (0.0612)  loss_mask: 1.6304 (1.5313)  loss_objectness: 0.1318 (0.2927)  loss_rpn_box_reg: 0.0091 (0.0348)  time: 8.6875  data: 0.0341\n",
      "Epoch: [0]  [ 20/219]  eta: 0:29:08  lr: 0.000486  loss: 0.9890 (1.6512)  loss_classifier: 0.1552 (0.2403)  loss_box_reg: 0.0541 (0.0609)  loss_mask: 0.5819 (1.1092)  loss_objectness: 0.0807 (0.2128)  loss_rpn_box_reg: 0.0067 (0.0280)  time: 8.5472  data: 0.0049\n",
      "Epoch: [0]  [ 30/219]  eta: 0:29:08  lr: 0.000715  loss: 0.7046 (1.3325)  loss_classifier: 0.0731 (0.1897)  loss_box_reg: 0.0615 (0.0631)  loss_mask: 0.4536 (0.8994)  loss_objectness: 0.0380 (0.1564)  loss_rpn_box_reg: 0.0085 (0.0240)  time: 9.5652  data: 0.0037\n",
      "Epoch: [0]  [ 40/219]  eta: 0:27:48  lr: 0.000944  loss: 0.5129 (1.1320)  loss_classifier: 0.0933 (0.1685)  loss_box_reg: 0.0798 (0.0719)  loss_mask: 0.2931 (0.7420)  loss_objectness: 0.0313 (0.1292)  loss_rpn_box_reg: 0.0073 (0.0205)  time: 9.8833  data: 0.0036\n",
      "Epoch: [0]  [ 50/219]  eta: 0:26:13  lr: 0.001174  loss: 0.4823 (1.0033)  loss_classifier: 0.0919 (0.1526)  loss_box_reg: 0.0952 (0.0775)  loss_mask: 0.2291 (0.6408)  loss_objectness: 0.0271 (0.1113)  loss_rpn_box_reg: 0.0052 (0.0211)  time: 9.3993  data: 0.0037\n",
      "Epoch: [0]  [ 60/219]  eta: 0:24:32  lr: 0.001403  loss: 0.4533 (0.9270)  loss_classifier: 0.0623 (0.1375)  loss_box_reg: 0.0809 (0.0778)  loss_mask: 0.2369 (0.5798)  loss_objectness: 0.0163 (0.1076)  loss_rpn_box_reg: 0.0068 (0.0243)  time: 9.1400  data: 0.0037\n",
      "Epoch: [0]  [ 70/219]  eta: 0:23:31  lr: 0.001632  loss: 0.4168 (0.8536)  loss_classifier: 0.0561 (0.1265)  loss_box_reg: 0.0737 (0.0783)  loss_mask: 0.2373 (0.5292)  loss_objectness: 0.0192 (0.0973)  loss_rpn_box_reg: 0.0061 (0.0223)  time: 9.8810  data: 0.0036\n",
      "Epoch: [0]  [ 80/219]  eta: 0:22:02  lr: 0.001861  loss: 0.3999 (0.8038)  loss_classifier: 0.0529 (0.1181)  loss_box_reg: 0.0828 (0.0813)  loss_mask: 0.2116 (0.4913)  loss_objectness: 0.0214 (0.0878)  loss_rpn_box_reg: 0.0056 (0.0254)  time: 10.2887  data: 0.0036\n",
      "Epoch: [0]  [ 90/219]  eta: 0:20:29  lr: 0.002090  loss: 0.3867 (0.7598)  loss_classifier: 0.0535 (0.1116)  loss_box_reg: 0.0976 (0.0864)  loss_mask: 0.1712 (0.4567)  loss_objectness: 0.0102 (0.0798)  loss_rpn_box_reg: 0.0069 (0.0253)  time: 9.7571  data: 0.0036\n",
      "Epoch: [0]  [100/219]  eta: 0:19:08  lr: 0.002319  loss: 0.3745 (0.7190)  loss_classifier: 0.0515 (0.1051)  loss_box_reg: 0.1208 (0.0880)  loss_mask: 0.1603 (0.4289)  loss_objectness: 0.0064 (0.0726)  loss_rpn_box_reg: 0.0100 (0.0244)  time: 10.1795  data: 0.0036\n",
      "Epoch: [0]  [110/219]  eta: 0:17:36  lr: 0.002548  loss: 0.3639 (0.6869)  loss_classifier: 0.0472 (0.1000)  loss_box_reg: 0.0999 (0.0900)  loss_mask: 0.1692 (0.4061)  loss_objectness: 0.0049 (0.0665)  loss_rpn_box_reg: 0.0053 (0.0243)  time: 10.4114  data: 0.0036\n",
      "Epoch: [0]  [120/219]  eta: 0:16:06  lr: 0.002777  loss: 0.3542 (0.6678)  loss_classifier: 0.0387 (0.0949)  loss_box_reg: 0.0963 (0.0894)  loss_mask: 0.1824 (0.3872)  loss_objectness: 0.0042 (0.0717)  loss_rpn_box_reg: 0.0059 (0.0247)  time: 10.3286  data: 0.0037\n",
      "Epoch: [0]  [130/219]  eta: 0:14:30  lr: 0.003007  loss: 0.3340 (0.6427)  loss_classifier: 0.0355 (0.0908)  loss_box_reg: 0.0762 (0.0884)  loss_mask: 0.1712 (0.3718)  loss_objectness: 0.0049 (0.0679)  loss_rpn_box_reg: 0.0050 (0.0239)  time: 10.2493  data: 0.0038\n",
      "Epoch: [0]  [140/219]  eta: 0:12:50  lr: 0.003236  loss: 0.3532 (0.6278)  loss_classifier: 0.0455 (0.0882)  loss_box_reg: 0.0816 (0.0877)  loss_mask: 0.1790 (0.3596)  loss_objectness: 0.0120 (0.0672)  loss_rpn_box_reg: 0.0048 (0.0252)  time: 9.6739  data: 0.0038\n",
      "Epoch: [0]  [150/219]  eta: 0:11:10  lr: 0.003465  loss: 0.3492 (0.6124)  loss_classifier: 0.0457 (0.0855)  loss_box_reg: 0.0773 (0.0872)  loss_mask: 0.1805 (0.3495)  loss_objectness: 0.0131 (0.0639)  loss_rpn_box_reg: 0.0054 (0.0263)  time: 9.2740  data: 0.0037\n",
      "Epoch: [0]  [160/219]  eta: 0:09:30  lr: 0.003694  loss: 0.3319 (0.5979)  loss_classifier: 0.0434 (0.0836)  loss_box_reg: 0.0758 (0.0867)  loss_mask: 0.1805 (0.3407)  loss_objectness: 0.0095 (0.0604)  loss_rpn_box_reg: 0.0065 (0.0265)  time: 9.1097  data: 0.0039\n",
      "Epoch: [0]  [170/219]  eta: 0:07:55  lr: 0.003923  loss: 0.3842 (0.5919)  loss_classifier: 0.0329 (0.0804)  loss_box_reg: 0.0581 (0.0845)  loss_mask: 0.2204 (0.3360)  loss_objectness: 0.0105 (0.0601)  loss_rpn_box_reg: 0.0121 (0.0309)  time: 9.7194  data: 0.0043\n",
      "Epoch: [0]  [180/219]  eta: 0:06:18  lr: 0.004152  loss: 0.3582 (0.5785)  loss_classifier: 0.0258 (0.0778)  loss_box_reg: 0.0416 (0.0829)  loss_mask: 0.1877 (0.3276)  loss_objectness: 0.0105 (0.0575)  loss_rpn_box_reg: 0.0127 (0.0327)  time: 10.0550  data: 0.0041\n",
      "Epoch: [0]  [190/219]  eta: 0:04:41  lr: 0.004381  loss: 0.3232 (0.5673)  loss_classifier: 0.0310 (0.0758)  loss_box_reg: 0.0670 (0.0822)  loss_mask: 0.1866 (0.3224)  loss_objectness: 0.0080 (0.0548)  loss_rpn_box_reg: 0.0051 (0.0321)  time: 9.6776  data: 0.0039\n",
      "Epoch: [0]  [200/219]  eta: 0:03:03  lr: 0.004610  loss: 0.3130 (0.5529)  loss_classifier: 0.0404 (0.0740)  loss_box_reg: 0.0708 (0.0813)  loss_mask: 0.1834 (0.3138)  loss_objectness: 0.0026 (0.0523)  loss_rpn_box_reg: 0.0052 (0.0314)  time: 9.0250  data: 0.0040\n",
      "Epoch: [0]  [210/219]  eta: 0:01:26  lr: 0.004840  loss: 0.2802 (0.5422)  loss_classifier: 0.0314 (0.0722)  loss_box_reg: 0.0616 (0.0807)  loss_mask: 0.1473 (0.3090)  loss_objectness: 0.0018 (0.0500)  loss_rpn_box_reg: 0.0050 (0.0302)  time: 9.0245  data: 0.0038\n",
      "Epoch: [0]  [218/219]  eta: 0:00:09  lr: 0.005000  loss: 0.3124 (0.5365)  loss_classifier: 0.0314 (0.0711)  loss_box_reg: 0.0616 (0.0804)  loss_mask: 0.2092 (0.3067)  loss_objectness: 0.0015 (0.0483)  loss_rpn_box_reg: 0.0034 (0.0301)  time: 9.3419  data: 0.0037\n",
      "Epoch: [0] Total time: 0:35:06 (9.6187 s / it)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-973c2f23a2e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-973c2f23a2e5>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;31m# evaluate on the test dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_loader_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"That's it!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/nlp/lib/python3.6/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/FB_synthesizer/engine.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, data_loader, device)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mmodel_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/nlp/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(device)\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m     \"\"\"\n\u001b[0;32m--> 378\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    379\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_synchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/code/nlp/lib/python3.6/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 10010). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "# Sample code from the TorchVision 0.3 Object Detection Finetuning Tutorial\n",
    "# http://pytorch.org/tutorials/intermediate/torchvision_tutorial.html\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "from torchvision.models.detection.mask_rcnn import MaskRCNNPredictor\n",
    "import utils\n",
    "from engine import train_one_epoch, evaluate\n",
    "\n",
    "import transforms as T\n",
    "\n",
    "Data_Folder_URL = \"FB_Xray\"\n",
    "PNG_Image_URL = \"PNGImages\"\n",
    "PNG_Mask_URL = \"Masks\"\n",
    "\n",
    "class PennFudanDataset(object):\n",
    "    def __init__(self, root, transforms):\n",
    "        self.root = root\n",
    "        self.transforms = transforms\n",
    "        # load all image files, sorting them to\n",
    "        # ensure that they are aligned\n",
    "        self.imgs = list(sorted(os.listdir(os.path.join(root, PNG_Image_URL))))\n",
    "        self.masks = list(sorted(os.listdir(os.path.join(root, PNG_Mask_URL))))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # load images ad masks\n",
    "        img_path = os.path.join(self.root, PNG_Image_URL, self.imgs[idx])\n",
    "        mask_path = os.path.join(self.root, PNG_Mask_URL, self.masks[idx])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "        # note that we haven't converted the mask to RGB,\n",
    "        # because each color corresponds to a different instance\n",
    "        # with 0 being background\n",
    "        mask = Image.open(mask_path)\n",
    "\n",
    "        mask = np.array(mask)\n",
    "        # instances are encoded as different colors\n",
    "        obj_ids = np.unique(mask)\n",
    "        # first id is the background, so remove it\n",
    "        obj_ids = obj_ids[1:]\n",
    "\n",
    "        # split the color-encoded mask into a set\n",
    "        # of binary masks\n",
    "        masks = mask == obj_ids[:, None, None]\n",
    "\n",
    "        # get bounding box coordinates for each mask\n",
    "        num_objs = len(obj_ids)\n",
    "        boxes = []\n",
    "        for i in range(num_objs):\n",
    "            pos = np.where(masks[i])\n",
    "            xmin = np.min(pos[1])\n",
    "            xmax = np.max(pos[1])\n",
    "            ymin = np.min(pos[0])\n",
    "            ymax = np.max(pos[0])\n",
    "            boxes.append([xmin, ymin, xmax, ymax])\n",
    "\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        # there is only one class\n",
    "        labels = torch.ones((num_objs,), dtype=torch.int64)\n",
    "        masks = torch.as_tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        image_id = torch.tensor([idx])\n",
    "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        # suppose all instances are not crowd\n",
    "        iscrowd = torch.zeros((num_objs,), dtype=torch.int64)\n",
    "\n",
    "        target = {}\n",
    "        target[\"boxes\"] = boxes\n",
    "        target[\"labels\"] = labels\n",
    "        target[\"masks\"] = masks\n",
    "        target[\"image_id\"] = image_id\n",
    "        target[\"area\"] = area\n",
    "        target[\"iscrowd\"] = iscrowd\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            img, target = self.transforms(img, target)\n",
    "\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "def get_model_instance_segmentation(num_classes):\n",
    "    # load an instance segmentation model pre-trained pre-trained on COCO\n",
    "    model = torchvision.models.detection.maskrcnn_resnet50_fpn(pretrained=True)\n",
    "\n",
    "    # get number of input features for the classifier\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    # replace the pre-trained head with a new one\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "\n",
    "    # now get the number of input features for the mask classifier\n",
    "    in_features_mask = model.roi_heads.mask_predictor.conv5_mask.in_channels\n",
    "    hidden_layer = 256\n",
    "    # and replace the mask predictor with a new one\n",
    "    model.roi_heads.mask_predictor = MaskRCNNPredictor(in_features_mask,\n",
    "                                                       hidden_layer,\n",
    "                                                       num_classes)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_transform(train):\n",
    "    transforms = []\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "\n",
    "def main():\n",
    "    # train on the GPU or on the CPU, if a GPU is not available\n",
    "    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "    # our dataset has two classes only - background and person\n",
    "    num_classes = 2\n",
    "    # use our dataset and defined transformations\n",
    "    dataset = PennFudanDataset(Data_Folder_URL, get_transform(train=True))\n",
    "    dataset_test = PennFudanDataset(Data_Folder_URL, get_transform(train=False))\n",
    "\n",
    "    # split the dataset in train and test set\n",
    "    indices = torch.randperm(len(dataset)).tolist()\n",
    "    dataset = torch.utils.data.Subset(dataset, indices[:-50])\n",
    "    dataset_test = torch.utils.data.Subset(dataset_test, indices[-50:])\n",
    "\n",
    "    # define training and validation data loaders\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=2, shuffle=True, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    data_loader_test = torch.utils.data.DataLoader(\n",
    "        dataset_test, batch_size=1, shuffle=False, num_workers=4,\n",
    "        collate_fn=utils.collate_fn)\n",
    "\n",
    "    # get the model using our helper function\n",
    "    model = get_model_instance_segmentation(num_classes)\n",
    "\n",
    "    # move model to the right device\n",
    "    model.to(device)\n",
    "\n",
    "    # construct an optimizer\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "    optimizer = torch.optim.SGD(params, lr=0.005,\n",
    "                                momentum=0.9, weight_decay=0.0005)\n",
    "    # and a learning rate scheduler\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
    "                                                   step_size=3,\n",
    "                                                   gamma=0.1)\n",
    "\n",
    "    # let's train it for 10 epochs\n",
    "    num_epochs = 10\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # train for one epoch, printing every 10 iterations\n",
    "        train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
    "        # update the learning rate\n",
    "        lr_scheduler.step()\n",
    "        # evaluate on the test dataset\n",
    "        evaluate(model, data_loader_test, device=device)\n",
    "\n",
    "    print(\"That's it!\")\n",
    "    return model\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    model = main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
